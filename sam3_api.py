# Copyright (c) Meta Platforms, Inc. and affiliates.
# SAM3 API - FastAPI wrapper for SAM3 2D Interactive Segmentation (SAM1 task)

from fastapi import FastAPI, File, UploadFile, HTTPException, Form
from fastapi.responses import FileResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import os
import sys
import uuid
import shutil
import tempfile
import numpy as np
from PIL import Image
from typing import List, Optional
import json

app = FastAPI(title="SAM3 API", description="2D Interactive Segmentation using SAM3")

# CORS è¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# è¨­å®šç’°å¢ƒè®Šæ•¸
os.environ["PYTORCH_ENABLE_MPS_FALLBACK"] = "1"

# è‡¨æ™‚è¼¸å‡ºç›®éŒ„
OUTPUT_DIR = tempfile.mkdtemp()
print(f"SAM3 è¼¸å‡ºç›®éŒ„: {OUTPUT_DIR}")

# å…¨åŸŸæ¨¡å‹èˆ‡è™•ç†å™¨
model = None
processor = None
device = None

@app.on_event("startup")
async def load_model():
    global model, processor, device
    try:
        import torch
        import sam3
        from sam3 import build_sam3_image_model
        from sam3.model.sam3_image_processor import Sam3Processor

        # é¸æ“‡è¨­å‚™
        if torch.cuda.is_available():
            device = torch.device("cuda")
            torch.autocast("cuda", dtype=torch.bfloat16).__enter__()
            if torch.cuda.get_device_properties(0).major >= 8:
                torch.backends.cuda.matmul.allow_tf32 = True
                torch.backends.cudnn.allow_tf32 = True
        elif torch.backends.mps.is_available():
            device = torch.device("mps")
        else:
            device = torch.device("cpu")

        print(f"ä½¿ç”¨è¨­å‚™: {device}")

        # å–å¾— sam3 root è·¯å¾‘
        sam3_root = os.path.join(os.path.dirname(sam3.__file__), "..")
        bpe_path = f"{sam3_root}/assets/bpe_simple_vocab_16e6.txt.gz"

        # è¼‰å…¥æ¨¡å‹
        model = build_sam3_image_model(bpe_path=bpe_path, enable_inst_interactivity=True)
        processor = Sam3Processor(model)

        print("âœ… SAM3 æ¨¡å‹è¼‰å…¥æˆåŠŸ")
    except Exception as e:
        print(f"âŒ SAM3 æ¨¡å‹è¼‰å…¥å¤±æ•—: {str(e)}")
        raise RuntimeError(f"SAM3 æ¨¡å‹è¼‰å…¥å¤±æ•—: {str(e)}")


# å„²å­˜ inference_state çš„å­—å…¸ï¼ˆç”¨æ–¼å¤šæ­¥é©Ÿäº’å‹•ï¼‰
inference_states = {}


@app.post("/set_image")
async def set_image(image: UploadFile = File(..., description="è¦åˆ†å‰²çš„åœ–ç‰‡")):
    """
    è¨­å®šè¦é€²è¡Œåˆ†å‰²çš„åœ–ç‰‡ï¼Œè¿”å› session_id ç”¨æ–¼å¾ŒçºŒé æ¸¬ã€‚
    
    é€™æœƒè¨ˆç®—åœ–ç‰‡çš„ embeddingï¼Œå¾ŒçºŒå¯ä»¥ç”¨ session_id é€²è¡Œå¤šæ¬¡åˆ†å‰²é æ¸¬ã€‚
    """
    global model, processor, inference_states

    if model is None or processor is None:
        raise HTTPException(status_code=503, detail="æ¨¡å‹å°šæœªè¼‰å…¥")

    try:
        session_id = str(uuid.uuid4())
        work_dir = os.path.join(OUTPUT_DIR, session_id)
        os.makedirs(work_dir, exist_ok=True)

        # å„²å­˜åœ–ç‰‡
        image_path = os.path.join(work_dir, "image.png")
        with open(image_path, "wb") as buffer:
            shutil.copyfileobj(image.file, buffer)

        # è¼‰å…¥åœ–ç‰‡ä¸¦è¨­å®šåˆ°è™•ç†å™¨
        pil_image = Image.open(image_path)
        inference_state = processor.set_image(pil_image)

        # å„²å­˜ inference_state
        inference_states[session_id] = {
            "state": inference_state,
            "image_path": image_path,
            "image_size": pil_image.size,  # (width, height)
            "last_logits": None
        }

        return {
            "session_id": session_id,
            "image_size": {"width": pil_image.size[0], "height": pil_image.size[1]},
            "message": "åœ–ç‰‡å·²è¨­å®šï¼Œå¯ä»¥é–‹å§‹åˆ†å‰²"
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/predict")
async def predict(
    session_id: str = Form(..., description="set_image è¿”å›çš„ session_id"),
    point_coords: str = Form(None, description="é»åº§æ¨™ JSONï¼Œæ ¼å¼: [[x1,y1], [x2,y2], ...]"),
    point_labels: str = Form(None, description="é»æ¨™ç±¤ JSONï¼Œæ ¼å¼: [1, 0, ...]ï¼ˆ1=å‰æ™¯, 0=èƒŒæ™¯ï¼‰"),
    box: str = Form(None, description="æ¡†åº§æ¨™ JSONï¼Œæ ¼å¼: [x1, y1, x2, y2]"),
    use_previous_mask: bool = Form(False, description="æ˜¯å¦ä½¿ç”¨ä¸Šä¸€æ¬¡é æ¸¬çš„ mask ä½œç‚ºè¼¸å…¥"),
    multimask_output: bool = Form(True, description="æ˜¯å¦è¼¸å‡ºå¤šå€‹ mask")
):
    """
    æ ¹æ“šé»æˆ–æ¡†æç¤ºé€²è¡Œåˆ†å‰²é æ¸¬ã€‚
    
    Returns:
        - masks: äºŒé€²åˆ¶ mask åœ–ç‰‡ (PNG)
        - scores: æ¯å€‹ mask çš„åˆ†æ•¸
    """
    global model, inference_states

    if model is None:
        raise HTTPException(status_code=503, detail="æ¨¡å‹å°šæœªè¼‰å…¥")

    if session_id not in inference_states:
        raise HTTPException(status_code=404, detail="Session ä¸å­˜åœ¨ï¼Œè«‹å…ˆå‘¼å« /set_image")

    try:
        session = inference_states[session_id]
        inference_state = session["state"]

        # è§£ææç¤º
        input_point = None
        input_label = None
        input_box = None
        mask_input = None

        if point_coords:
            input_point = np.array(json.loads(point_coords))
        if point_labels:
            input_label = np.array(json.loads(point_labels))
        if box:
            input_box = np.array(json.loads(box))

        # ä½¿ç”¨ä¸Šä¸€æ¬¡çš„ mask
        if use_previous_mask and session.get("last_logits") is not None:
            last_logits = session["last_logits"]
            mask_input = last_logits[np.argmax(session.get("last_scores", [0])), :, :]
            mask_input = mask_input[None, :, :]

        # åŸ·è¡Œé æ¸¬
        masks, scores, logits = model.predict_inst(
            inference_state,
            point_coords=input_point,
            point_labels=input_label,
            box=input_box[None, :] if input_box is not None else None,
            mask_input=mask_input,
            multimask_output=multimask_output,
        )

        # æŒ‰åˆ†æ•¸æ’åº
        sorted_ind = np.argsort(scores)[::-1]
        masks = masks[sorted_ind]
        scores = scores[sorted_ind]
        logits = logits[sorted_ind]

        # å„²å­˜ logits ä¾›ä¸‹æ¬¡ä½¿ç”¨
        session["last_logits"] = logits
        session["last_scores"] = scores

        # å„²å­˜ mask åœ–ç‰‡
        work_dir = os.path.dirname(session["image_path"])
        mask_paths = []

        for i, mask in enumerate(masks):
            # è½‰æ›ç‚º PNG (0/255)
            mask_img = Image.fromarray((mask * 255).astype(np.uint8))
            mask_path = os.path.join(work_dir, f"mask_{i}.png")
            mask_img.save(mask_path)
            mask_paths.append(f"/download/{session_id}/mask_{i}.png")

        return {
            "session_id": session_id,
            "mask_count": len(masks),
            "masks": mask_paths,
            "scores": scores.tolist(),
            "best_mask": mask_paths[0] if mask_paths else None
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/predict_and_apply")
async def predict_and_apply(
    session_id: str = Form(...),
    point_coords: str = Form(None),
    point_labels: str = Form(None),
    use_previous_mask: bool = Form(False),
    return_rgba: bool = Form(True, description="æ˜¯å¦è¿”å› RGBA å»èƒŒåœ–")
):
    """
    åˆ†å‰²ä¸¦ç›´æ¥è¿”å›æœ€ä½³çš„ RGBA å»èƒŒåœ–ï¼ˆalpha = maskï¼‰
    """
    global model, inference_states

    if model is None:
        raise HTTPException(status_code=503, detail="æ¨¡å‹å°šæœªè¼‰å…¥")

    if session_id not in inference_states:
        raise HTTPException(status_code=404, detail="Session ä¸å­˜åœ¨")

    try:
        session = inference_states[session_id]
        inference_state = session["state"]

        # è§£ææç¤º
        input_point = np.array(json.loads(point_coords)) if point_coords else None
        input_label = np.array(json.loads(point_labels)) if point_labels else None

        mask_input = None
        if use_previous_mask and session.get("last_logits") is not None:
            last_logits = session["last_logits"]
            mask_input = last_logits[np.argmax(session.get("last_scores", [0])), :, :]
            mask_input = mask_input[None, :, :]

        # é æ¸¬ï¼ˆå–®ä¸€è¼¸å‡ºï¼‰
        masks, scores, logits = model.predict_inst(
            inference_state,
            point_coords=input_point,
            point_labels=input_label,
            mask_input=mask_input,
            multimask_output=False,
        )

        # å„²å­˜
        session["last_logits"] = logits
        session["last_scores"] = scores

        best_mask = masks[0]
        work_dir = os.path.dirname(session["image_path"])

        if return_rgba:
            # è¼‰å…¥åŸåœ–ä¸¦å¥—ç”¨ mask æˆ RGBA
            original = Image.open(session["image_path"]).convert("RGBA")
            original_np = np.array(original)

            # å¥—ç”¨ mask ä½œç‚º alpha
            original_np[:, :, 3] = (best_mask * 255).astype(np.uint8)

            rgba_img = Image.fromarray(original_np)
            rgba_path = os.path.join(work_dir, "rgba_output.png")
            rgba_img.save(rgba_path)

            return {
                "session_id": session_id,
                "score": float(scores[0]),
                "rgba_image": f"/download/{session_id}/rgba_output.png",
                "mask": f"/download/{session_id}/mask_best.png"
            }
        else:
            mask_img = Image.fromarray((best_mask * 255).astype(np.uint8))
            mask_path = os.path.join(work_dir, "mask_best.png")
            mask_img.save(mask_path)

            return {
                "session_id": session_id,
                "score": float(scores[0]),
                "mask": f"/download/{session_id}/mask_best.png"
            }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.delete("/session/{session_id}")
async def delete_session(session_id: str):
    """åˆªé™¤ session ä¸¦æ¸…ç†è³‡æº"""
    if session_id in inference_states:
        work_dir = os.path.dirname(inference_states[session_id]["image_path"])
        shutil.rmtree(work_dir, ignore_errors=True)
        del inference_states[session_id]
        return {"message": "Session å·²åˆªé™¤"}
    else:
        raise HTTPException(status_code=404, detail="Session ä¸å­˜åœ¨")


@app.get("/download/{session_id}/{file_name}")
async def download_file(session_id: str, file_name: str):
    """ä¸‹è¼‰ç”Ÿæˆçš„æª”æ¡ˆ"""
    file_path = os.path.join(OUTPUT_DIR, session_id, file_name)
    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail="æ‰¾ä¸åˆ°æª”æ¡ˆ")
    return FileResponse(file_path, media_type='image/png', filename=file_name)


@app.get("/health")
async def health_check():
    """å¥åº·æª¢æŸ¥"""
    return {
        "status": "ok",
        "model_loaded": model is not None,
        "active_sessions": len(inference_states)
    }


@app.on_event("shutdown")
async def cleanup():
    """æ¸…ç†æ‰€æœ‰è‡¨æ™‚æª”æ¡ˆ"""
    shutil.rmtree(OUTPUT_DIR, ignore_errors=True)
    print("ğŸ§¹ SAM3 è‡¨æ™‚æª”æ¡ˆå·²æ¸…ç†")


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8002)
